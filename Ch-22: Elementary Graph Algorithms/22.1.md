# 22.1
## 22.1-1
**Out Degree**: O(|V|+|E|) or O(|V|) if we store list length. The idea is to iterate over all vertices(u ∈ V) and find length of each Adj[u]. Length of each Adj[u] indicates the outward edges or out degree    
**In Degree**: We iterate over all vertices and for vertex v ∈ Adj[u] we keep count of every time v occurs in Adj[u<sub>1</sub>], Adj[u<sub>2</sub>], Adj[u<sub>3</sub>], ... Adj[u<sub>V</sub>] as Count[v]. The final in degree of each vertex is given by Count[v]. Another way would also be *transpose* the graph and calculate out degree as above. Both cases runtime will be O(|V|+|E|). 

## 22.1-2
**Tree**: 
```
            1
    2               3
4       5       6       7
```
**AdjList**:   
1: 2 -> 3  
2: 1 -> 4 -> 5  
3: 1 -> 6 -> 7  
4: 2  
5: 2  
6: 3  
7: 3  
**AdjMatrix**:  
~ | 1 | 2 | 3 | 4 | 5 | 6 | 7
:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:
1 | 0 | 1 | 1 | 0 | 0 | 0 | 0
2 | 1 | 0 | 0 | 1 | 1 | 0 | 0
3 | 1 | 0 | 0 | 0 | 0 | 1 | 1
4 | 0 | 1 | 0 | 0 | 0 | 0 | 0 
5 | 0 | 1 | 0 | 0 | 0 | 0 | 0
6 | 0 | 0 | 1 | 0 | 0 | 0 | 0
7 | 0 | 0 | 1 | 0 | 0 | 0 | 0

## 22.1-3
**AdjList**: We iterate over all the vertices u in V. For each v in Adj[u<sub>1</sub>], Adj[u<sub>2</sub>]... we keep adding u<sub>1</sub>, u<sub>2</sub>... to NewAdj[v]
```
newAdj[V]
for(u=1; u<=|V|; u++):
    for( v in Adj[u]):
        newAdj[v].push_back(u)

Memory: O(|V| + |E|) Time: O(|V| + |E|)  
```

**AdjMatrix**:
Transpose the matrix. We assume 0-indexing

```
for(u=0; u<|V|; u++):
    for(v=u; v<Adj[u].length; v++):
        swap(Adj[u][v]);
```

## 22.1-4
We iterate over the vertices. For each u in V and v in Adj[u], there can be two cases -   
- u = v
- v occurs multiple times
Hence, create a new array Arr of size V(this is similar to hashmap except that V should always be in limits hence we are using array directly than hashing). The use of this array is to track parent of each vertex when iterating over Adj[parent]. If v==u or its visited before we skip it.
```
Arr[V]
newAdj[V]
for(u=1; u<=V; u++):
    for(v in Adj[u]):
        if(v==u):
            continue;
        else if(Arr[v] != u): <!-- Check if v is seen before-->
            <!-- Add v to Adj as its first seen -->
            newAdj[u].push_back(v)
            <!-- Set flag so we don't visit it again. -->
            Arr[v] = u

Memory: O(|V| + |E|)                    Time: O(|V| + |E|)
```

## 22.1-5
**AdjList**
Iterate over all vertices u in V and then for each v in Adj[u] add v' in newAdj[u] along with v.   
`u -> v -> v'`   
Memory: O(|V||E| + |V|)
Time: O(|V||E| + |V|)

**Matrix**:   
Use matrix multiplication to square the matrix. `O(|V|<sup>2.38</sup>)`  
 See: <link>https://stackoverflow.com/a/1944648  
Reasoning is that the square entry: `C[u][v] = A[u][k]*A[k][v] k=1..V i.e. C[u][v] will be non-zero if u -> k -> v exists as A[u][k] & A[k][v] both needs to be non-zero`

## 22.1-6
The key insight here is that if there is a vertex u in graph Adj with V vertices, then for it to be sink row u is all 0s and col u is all 1s except for Adj[u][u], 
```  
-->1  0  1  0  0                     -->1  0  1  0  0   
   1  1  1  0  1                        1  1  1  0  1  
   0  0  0  0  0 <--- sink              0  0  0  0  1  
   1  0  1  0  0                        1  0  1  0  1 
   0  0  1  0  0                        0  0  1  0  0 -- no sink
``` 
So we start from adj[0][0] and for every 1 we go to next row and for every 0 we go to next column. After we have reached the end of matrix, we just need to check if the current row is sink or not.
It can be proven that if uth row is sink is present we will always end at `uth row` and  `Vth column`.
```
i=0
j=0;
while (i<V && j<V):
    if (adj[i][j] == 1):
        i++;
    else:
        j++;
check(i) // check ith row is all 0s and ith column is all 1s except adj[i][i]

Memory: O(1)
Time: O(2V-1) + O(2V)  ~  O(V)
```

## 22.1-7
We can see that for any element  B<sub>ij</sub> of graph BB<sup>T</sup>,    
 B<sub>ij</sub> = $\sum_{k=1}^{E}$ b<sub>ik</sub>.b<sub>jk</sub>

 For i=j, that is diagnol elements:   
 B<sub>ij</sub> = $\sum_{k=1}^{E}$ (b<sub>ik</sub>)<sup>2</sup>   
 `i.e. the number of edges leaving or entering the vertex i`

 Otherwise,   
 b<sub>ik</sub>.b<sub>jk</sub> = -1, if there is edge k between i and j   
  b<sub>ik</sub>.b<sub>jk</sub>, in all other cases   
b<sub>ik</sub>.b<sub>jk</sub> cannot be 1, as same edge cannot leave or enter from two different vertices.   
Hence,    
B<sub>ij</sub> = -1*K, where K is number of edges b/w i and j   
`i.e. -1*(number of edges between vertex i and j)`

## 22.1-8
1. Expected time is O(1), same as finding element element in hash table.
2. Worst case can be O(V) (maximum size of hash table)   
Another disadvantage will be high memory, as we would need O(V) space for each hash table in order to have O(1) query time which results in O(V<sup>2</sup>) space.
3. We can use, a set(BST) or a sorted array to have deterministic O(lgV) time which is more than hashtable(disadvantage).